# Loss=NaN é—®é¢˜åˆ†ææŠ¥å‘Š

## ğŸ” é—®é¢˜æ¦‚è¿°

è®­ç»ƒè¿‡ç¨‹ä¸­ loss å˜ä¸º NaNï¼Œé€šå¸¸åœ¨è®­ç»ƒå¼€å§‹åä¸ä¹…ï¼ˆ5-6%ï¼‰å‡ºç°ã€‚

---

## ğŸ¯ æ½œåœ¨é—®é¢˜åˆ†æ

### 1. **æ•°æ®ç¼–ç é—®é¢˜** âš ï¸ **é«˜é£é™©**

**ä½ç½®**: `dataset.py` - `_encode_text_to_image`

**é—®é¢˜**:
- Token ID èŒƒå›´æ˜¯ `[0, 151643]`ï¼ˆvocab_sizeï¼‰
- ä½¿ç”¨ 256 è¿›åˆ¶åˆ†è§£ï¼š`r = token_id % 256`, `g = (token_id // 256) % 256`, `b = (token_id // 65536) % 256`
- **é—®é¢˜**ï¼šå½“ `token_id >= 16777216 (256^3)` æ—¶ï¼Œä¼šæº¢å‡ºï¼Œä½† vocab_size=151643 < 16777216ï¼Œæ‰€ä»¥ç†è®ºä¸Šä¸ä¼šæº¢å‡º
- **ä½†æ˜¯**ï¼šå¦‚æœ token_id è¶…å‡º vocab_sizeï¼ˆç‰¹æ®Š tokenï¼‰ï¼Œå¯èƒ½æ¥è¿‘æˆ–è¶…è¿‡ 256^3

**æ£€æŸ¥ç‚¹**:
```python
# robust_token2img.py ä¸­çš„ token_id_to_color
def token_id_to_color(self, token_id: int) -> Tuple[int, int, int]:
    if token_id < 0:
        raise ValueError(f"token_id {token_id} cannot be negative")
    r = token_id % 256
    g = (token_id // 256) % 256
    b = (token_id // (256 * 256)) % 256
    return (r, g, b)
```

**å¯èƒ½çš„é—®é¢˜**ï¼š
- å¦‚æœ token_id å¾ˆå¤§ï¼ˆæ¥è¿‘ 256^3ï¼‰ï¼Œb å€¼å¯èƒ½å¾ˆå¤§ï¼Œå¯¼è‡´é¢œè‰²å€¼å¼‚å¸¸
- å›¾åƒå½’ä¸€åŒ–åˆ° [0, 1] åï¼Œå¦‚æœåŸå§‹å€¼å¼‚å¸¸ï¼Œå¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®š

---

### 2. **æ¨¡å‹æ•°å€¼ç¨³å®šæ€§é—®é¢˜** âš ï¸ **é«˜é£é™©**

#### 2.1 RMSNorm é™¤æ³•é—®é¢˜

**ä½ç½®**: `model.py` - `RMSNorm.forward`

```python
def forward(self, x: torch.Tensor) -> torch.Tensor:
    norm = x.norm(dim=-1, keepdim=True) * (x.shape[-1] ** -0.5)
    return x / (norm + self.eps) * self.weight
```

**é—®é¢˜**:
- å¦‚æœ `x` å…¨ä¸º 0ï¼ˆpaddingï¼‰ï¼Œ`norm` å¯èƒ½ä¸º 0ï¼Œè™½ç„¶æœ‰ `eps=1e-6`ï¼Œä½†å¯èƒ½ä¸å¤Ÿ
- å¦‚æœ `x` ä¸­æœ‰ inf æˆ– nanï¼Œä¼šä¼ æ’­

#### 2.2 AdaLNZero Scale é—®é¢˜

**ä½ç½®**: `model.py` - `AdaLNZero.forward`

```python
def forward(self, x: torch.Tensor, c: torch.Tensor) -> torch.Tensor:
    shift = self.shift_mlp(c)
    scale = self.scale_mlp(c) + 1.0
    return self.norm(x) * scale.unsqueeze(1) + shift.unsqueeze(1)
```

**é—®é¢˜**:
- `scale_mlp` åˆå§‹åŒ–ä¸º 0ï¼Œæ‰€ä»¥åˆå§‹ `scale = 0 + 1.0 = 1.0`ï¼Œè¿™æ˜¯æ­£å¸¸çš„
- ä½†å¦‚æœè®­ç»ƒè¿‡ç¨‹ä¸­ `scale_mlp` è¾“å‡ºå¾ˆå¤§ï¼ˆæ­£æˆ–è´Ÿï¼‰ï¼Œ`scale` å¯èƒ½å¾ˆå¤§æˆ–ä¸ºè´Ÿï¼Œå¯¼è‡´æ•°å€¼ä¸ç¨³å®š

#### 2.3 Attention Mask é—®é¢˜

**ä½ç½®**: `model.py` - `MultiHeadAttention.forward`

```python
if attention_mask is not None:
    mask_expanded = attention_mask.unsqueeze(1).unsqueeze(2)  # [B, 1, 1, N]
    attn = attn.masked_fill(mask_expanded == 0, float('-inf'))
```

**é—®é¢˜**:
- å¦‚æœ `mask_expanded == 0` çš„ä½ç½®å¾ˆå¤šï¼Œ`attn` ä¸­ä¼šæœ‰å¾ˆå¤š `-inf`
- è™½ç„¶ softmax ä¼šå°† `-inf` è½¬æ¢ä¸º 0ï¼Œä½†å¦‚æœæ‰€æœ‰ä½ç½®éƒ½æ˜¯ `-inf`ï¼Œsoftmax å¯èƒ½äº§ç”Ÿ nan

#### 2.4 Attention Scale é—®é¢˜

**ä½ç½®**: `model.py` - `MultiHeadAttention.__init__`

```python
self.scale = self.head_dim ** -0.5
```

**é—®é¢˜**:
- å¦‚æœ `head_dim` å¾ˆå°ï¼Œ`scale` ä¼šå¾ˆå¤§
- å¯¹äº `embed_dim=768, num_heads=12`ï¼Œ`head_dim=64`ï¼Œ`scale=0.125`ï¼Œè¿™æ˜¯æ­£å¸¸çš„
- ä½†å¦‚æœ `head_dim` è®¡ç®—é”™è¯¯ï¼Œå¯èƒ½å¯¼è‡´ `scale` å¼‚å¸¸

---

### 3. **è®­ç»ƒè¿‡ç¨‹é—®é¢˜** âš ï¸ **é«˜é£é™©**

#### 3.1 å™ªå£°æ·»åŠ é—®é¢˜

**ä½ç½®**: `train.py` - `add_noise_to_timestep`

```python
def add_noise_to_timestep(x: torch.Tensor, t: torch.Tensor, noise_schedule: str = 'linear') -> Tuple[torch.Tensor, torch.Tensor]:
    B = x.shape[0]
    device = x.device
    
    noise = torch.randn_like(x)
    
    if noise_schedule == 'linear':
        alpha = 1.0 - (t.float() / 1000.0)
    else:
        alpha = 0.5 * (1 + torch.cos(torch.pi * t.float() / 1000.0))
    
    alpha = alpha.view(B, 1, 1, 1)
    noisy = alpha * x + (1 - alpha) * noise
    
    return noisy, noise
```

**é—®é¢˜**:
- `t` çš„èŒƒå›´æ˜¯ `[0, 999]`ï¼ˆ`torch.randint(0, 1000, ...)`ï¼‰
- `alpha = 1.0 - (t / 1000.0)`ï¼ŒèŒƒå›´æ˜¯ `[0.001, 1.0]`
- å½“ `t=999` æ—¶ï¼Œ`alpha=0.001`ï¼Œ`noisy = 0.001 * x + 0.999 * noise`
- å¦‚æœ `x` ä¸­æœ‰å¼‚å¸¸å€¼ï¼ˆinf/nanï¼‰ï¼Œä¼šä¼ æ’­åˆ° `noisy`

#### 3.2 Loss è®¡ç®—é—®é¢˜

**ä½ç½®**: `train.py` - `train_epoch_optimized`

```python
# è®¡ç®— masked loss
diff = (clean_pred_img - clean) ** 2
masked_diff = diff * mask_expanded
loss = masked_diff.sum() / (mask_expanded.sum() + 1e-8)  # å½’ä¸€åŒ–
loss = loss / gradient_accumulation_steps
```

**é—®é¢˜**:
- å¦‚æœ `clean_pred_img` æˆ– `clean` ä¸­æœ‰ inf/nanï¼Œ`diff` ä¼šåŒ…å« inf/nan
- å¦‚æœ `mask_expanded.sum() == 0`ï¼ˆæ‰€æœ‰åƒç´ éƒ½æ˜¯ paddingï¼‰ï¼Œè™½ç„¶æœ‰ `1e-8`ï¼Œä½†å¦‚æœ `masked_diff.sum()` ä¹Ÿæ˜¯ 0ï¼Œ`loss = 0 / 1e-8 = 0`ï¼Œè¿™æ˜¯æ­£å¸¸çš„
- ä½†å¦‚æœ `masked_diff.sum()` æ˜¯ infï¼Œ`loss = inf / 1e-8 = inf`

#### 3.3 å­¦ä¹ ç‡é—®é¢˜

**å½“å‰è®¾ç½®**: `LR=1e-4`ï¼ˆtrain_test.shï¼‰

**é—®é¢˜**:
- å¯¹äºæ‰©æ•£æ¨¡å‹ï¼Œ`1e-4` å¯èƒ½åå¤§
- å¦‚æœæ¢¯åº¦å¾ˆå¤§ï¼Œ`lr * grad` å¯èƒ½å¯¼è‡´å‚æ•°æ›´æ–°è¿‡å¤§ï¼Œäº§ç”Ÿ inf/nan

#### 3.4 æ¢¯åº¦è£å‰ªé—®é¢˜

**å½“å‰è®¾ç½®**: `MAX_GRAD_NORM=1.0`

**é—®é¢˜**:
- æ¢¯åº¦è£å‰ªåœ¨ AMP æ¨¡å¼ä¸‹éœ€è¦å…ˆ `scaler.unscale_()`ï¼Œä»£ç ä¸­å·²ç»åšäº†
- ä½†å¦‚æœæ¢¯åº¦æœ¬èº«åŒ…å« inf/nanï¼Œè£å‰ªå¯èƒ½æ— æ•ˆ

---

### 4. **æ··åˆç²¾åº¦è®­ç»ƒé—®é¢˜** âš ï¸ **ä¸­ç­‰é£é™©**

**ä½ç½®**: `train.py` - AMP context

**é—®é¢˜**:
- æ··åˆç²¾åº¦è®­ç»ƒå¯èƒ½å¯¼è‡´æ•°å€¼ç²¾åº¦æŸå¤±
- å¦‚æœæŸäº›æ“ä½œåœ¨ fp16 ä¸‹ä¸ç¨³å®šï¼Œå¯èƒ½äº§ç”Ÿ inf/nan
- ç‰¹åˆ«æ˜¯ RMSNorm ä¸­çš„é™¤æ³•æ“ä½œ

---

## ğŸ”§ ä¿®å¤å»ºè®®

### ä¼˜å…ˆçº§ 1: æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥

1. **åœ¨ loss è®¡ç®—å‰æ£€æŸ¥è¾“å…¥**:
```python
# æ£€æŸ¥ clean_pred_img å’Œ clean æ˜¯å¦åŒ…å« nan/inf
if torch.isnan(clean_pred_img).any() or torch.isinf(clean_pred_img).any():
    print(f"Warning: clean_pred_img contains nan/inf at batch {batch_idx}")
    continue

if torch.isnan(clean).any() or torch.isinf(clean).any():
    print(f"Warning: clean contains nan/inf at batch {batch_idx}")
    continue
```

2. **åœ¨æ¨¡å‹è¾“å‡ºåæ£€æŸ¥**:
```python
clean_pred = model(noisy_target, t, condition=None, mask=mask)
if torch.isnan(clean_pred).any() or torch.isinf(clean_pred).any():
    print(f"Warning: model output contains nan/inf at batch {batch_idx}")
    continue
```

### ä¼˜å…ˆçº§ 2: ä¿®å¤ RMSNorm

```python
def forward(self, x: torch.Tensor) -> torch.Tensor:
    # æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
    if torch.isnan(x).any() or torch.isinf(x).any():
        print("Warning: RMSNorm input contains nan/inf")
        x = torch.nan_to_num(x, nan=0.0, posinf=1e6, neginf=-1e6)
    
    norm = x.norm(dim=-1, keepdim=True) * (x.shape[-1] ** -0.5)
    # ç¡®ä¿ norm ä¸ä¼šå¤ªå°
    norm = torch.clamp(norm, min=self.eps)
    return x / norm * self.weight
```

### ä¼˜å…ˆçº§ 3: é™ä½å­¦ä¹ ç‡

```bash
# train_test.sh
LR=1e-5  # ä» 1e-4 é™ä½åˆ° 1e-5
```

### ä¼˜å…ˆçº§ 4: å¢å¼ºæ¢¯åº¦è£å‰ª

```python
# åœ¨æ¢¯åº¦è£å‰ªå‰æ£€æŸ¥
if use_amp:
    scaler.unscale_(optimizer)
    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å« nan/inf
    for name, param in model.named_parameters():
        if param.grad is not None:
            if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():
                print(f"Warning: gradient contains nan/inf in {name}")
                param.grad.zero_()
    
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
    scaler.step(optimizer)
    scaler.update()
```

### ä¼˜å…ˆçº§ 5: ä¿®å¤ Attention Mask

```python
# ç¡®ä¿ä¸ä¼šæ‰€æœ‰ä½ç½®éƒ½æ˜¯ -inf
if attention_mask is not None:
    mask_expanded = attention_mask.unsqueeze(1).unsqueeze(2)
    attn = attn.masked_fill(mask_expanded == 0, float('-inf'))
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä½ç½®éƒ½æ˜¯ -inf
    if (attn == float('-inf')).all():
        # å¦‚æœæ‰€æœ‰ä½ç½®éƒ½æ˜¯ -infï¼Œè®¾ç½®ä¸ºå‡åŒ€åˆ†å¸ƒ
        attn = torch.zeros_like(attn)
    else:
        attn = attn.softmax(dim=-1)
```

---

## ğŸ¯ æœ€å¯èƒ½çš„åŸå› 

åŸºäºåˆ†æï¼Œ**æœ€å¯èƒ½çš„åŸå› æ˜¯**ï¼š

1. **æ¨¡å‹è¾“å‡ºåŒ…å« inf/nan**ï¼ˆå¯èƒ½æ˜¯ RMSNorm æˆ– AdaLNZero çš„æ•°å€¼ä¸ç¨³å®šï¼‰
2. **å­¦ä¹ ç‡è¿‡å¤§**ï¼ˆ1e-4 å¯¹äºæ‰©æ•£æ¨¡å‹å¯èƒ½åå¤§ï¼‰
3. **æ•°æ®ç¼–ç é—®é¢˜**ï¼ˆè™½ç„¶ç†è®ºä¸Šä¸ä¼šæº¢å‡ºï¼Œä½†éœ€è¦éªŒè¯ï¼‰

---

## ğŸ“ è°ƒè¯•æ­¥éª¤

1. **æ·»åŠ æ•°å€¼æ£€æŸ¥**ï¼šåœ¨å…³é”®ä½ç½®æ·»åŠ  nan/inf æ£€æŸ¥
2. **é™ä½å­¦ä¹ ç‡**ï¼šä» 1e-4 é™ä½åˆ° 1e-5 æˆ– 5e-6
3. **æ£€æŸ¥æ•°æ®**ï¼šéªŒè¯ token_id èŒƒå›´å’Œé¢œè‰²ç¼–ç 
4. **ç¦ç”¨æ··åˆç²¾åº¦**ï¼šæµ‹è¯•æ˜¯å¦ä¸ AMP ç›¸å…³
5. **ç®€åŒ–æ¨¡å‹**ï¼šä½¿ç”¨æ›´å°çš„æ¨¡å‹æµ‹è¯•

---

**ä¿®æ”¹æ—¥æœŸ**: 2024-12-15
