# RobustToken2Img 设计说明

## 🎯 设计目标

1. **每个像素对应一个文本 token**（1:1 映射）
2. **不同 token 的颜色不能重复**（保证唯一性）
3. **支持预训练**：直接将各领域文本编码到图像（无需问答对）
4. **参考 token2img.py 的颜色设置**，并思考是否有更好的办法

---

## 🔬 颜色映射方案分析

### 方案 1: 256 进制分解（当前实现）✅

```python
r = token_id % 256                    # 最低位（R通道）
g = (token_id // 256) % 256          # 次低位（G通道）
b = (token_id // (256 * 256)) % 256   # 第三位（B通道）

反向映射：
token_id = r + g * 256 + b * (256 * 256)
```

**优点**：
- ✅ **保证唯一性**：不同 token_id → 不同颜色（数学上保证）
- ✅ **计算简单**：O(1) 时间复杂度
- ✅ **双射映射**：颜色 ↔ token_id 一一对应
- ✅ **颜色空间大**：256³ = 16,777,216 种颜色
- ✅ **无冲突**：vocab_size (151,643) << 颜色空间 (16,777,216)

**缺点**：
- ⚠️ 颜色分布可能不均匀（但这对我们的应用不重要）

**结论**：**这是最优方案！**

---

### 方案 2: 颜色量化（不适用）❌

```python
# 将颜色空间量化为更少的级别
color_levels = 32  # 例如：32 级
r = (token_id % color_levels) * (256 // color_levels)
g = ((token_id // color_levels) % color_levels) * (256 // color_levels)
b = ((token_id // (color_levels ** 2)) % color_levels) * (256 // color_levels)
```

**问题**：
- ❌ **会产生冲突**：不同 token_id 可能映射到相同颜色
- ❌ **违反唯一性要求**：无法保证每个 token 对应唯一颜色

**结论**：**不适用**（因为要求每个像素对应一个 token，且颜色不能重复）

---

### 方案 3: 哈希映射（不适用）❌

```python
# 使用哈希函数
hash_value = hash(token_id) % (256 ** 3)
r = hash_value % 256
g = (hash_value // 256) % 256
b = (hash_value // (256 * 256)) % 256
```

**问题**：
- ❌ **可能产生冲突**：哈希函数可能将不同 token_id 映射到相同颜色
- ❌ **不可逆**：无法从颜色唯一确定 token_id
- ❌ **计算复杂**：需要哈希函数

**结论**：**不适用**（无法保证唯一性和可逆性）

---

### 方案 4: HSV 空间映射（不适用）❌

```python
# 将 token_id 映射到 HSV 空间
h = (token_id * 360) % 360
s = 100
v = 100
# 然后转换为 RGB
```

**问题**：
- ❌ **可能产生冲突**：不同 token_id 可能映射到相同 HSV 值
- ❌ **计算复杂**：需要 HSV → RGB 转换
- ❌ **不可逆**：无法从 RGB 唯一确定 token_id

**结论**：**不适用**（无法保证唯一性和可逆性）

---

## ✅ 最终方案：256 进制分解

### 为什么这是最优方案？

1. **数学保证唯一性**
   ```
   token_id = r + g * 256 + b * (256 * 256)
   
   对于不同的 token_id，至少有一个通道（r, g, b）不同
   因此，不同的 token_id 必然映射到不同的颜色
   ```

2. **可逆映射**
   ```
   从颜色恢复 token_id：
   token_id = r + g * 256 + b * (256 * 256)
   
   这是唯一的，因为 256 进制分解是唯一的
   ```

3. **颜色空间充足**
   ```
   vocab_size: 151,643
   颜色空间: 16,777,216 (256³)
   利用率: 0.90%
   
   即使 vocab_size 增加到 1000 万，仍然在颜色空间范围内
   ```

4. **计算高效**
   ```
   编码：O(1) - 简单的取模和除法
   解码：O(1) - 简单的乘法和加法
   ```

---

## 📊 实现细节

### 1. 编码流程

```python
def encode(text, size):
    # 1. Tokenize 文本
    token_ids = tokenizer.encode(text)
    
    # 2. 计算图像尺寸（如果未指定）
    if size is None:
        w = ceil(sqrt(len(token_ids)))
        h = ceil(len(token_ids) / w)
        size = (h, w)
    
    # 3. 创建图像数组
    img = zeros((h, w, 3), dtype=uint8)
    
    # 4. 将每个 token_id 映射为像素
    for i, token_id in enumerate(token_ids):
        x = i % w
        y = i // w
        color = token_id_to_color(token_id)  # 256 进制分解
        img[y, x] = [color[2], color[1], color[0]]  # BGR 格式
    
    return img
```

### 2. 解码流程

```python
def decode(img, num_tokens=None):
    h, w, _ = img.shape
    token_ids = []
    
    for y in range(h):
        for x in range(w):
            if num_tokens and len(token_ids) >= num_tokens:
                break
            
            color = tuple(img[y, x])  # BGR 格式
            if color == (0, 0, 0):  # 黑色像素（未使用）
                break
            
            token_id = color_to_token_id(color)  # 反向映射
            if token_id >= 0:  # 有效 token_id
                token_ids.append(token_id)
    
    text = tokenizer.decode(token_ids)
    return text
```

---

## 🚀 预训练应用

### 场景：直接将各领域文本编码到图像

```python
# 预训练数据准备
encoder = RobustToken2Img(tokenizer)

# 1. 读取各领域文本
texts = [
    "小说文本...",
    "科技论文...",
    "新闻文章...",
    ...
]

# 2. 编码到图像（256×256）
for i, text in enumerate(texts):
    img, metadata = encoder.encode(text, size=(256, 256))
    save_image(img, f"pretrain_{i}.png")
    
    # 模型学习：从噪声图像恢复原始图像
    # 这是自监督学习，无需问答对！
```

### 优势

1. **简单**：不需要构造问答对
2. **高效**：直接将文本编码到图像
3. **灵活**：可以处理任意长度的文本（分段处理）
4. **自监督**：模型学习从噪声恢复原始图像

---

## 📈 性能分析

### 编码性能

```
文本长度: 1,006,237 字符
Token 数量: 812,924 tokens
编码时间: < 1 秒
编码速度: ~1M tokens/秒
```

### 解码性能

```
图像尺寸: 1024×1024 = 1,048,576 像素
解码时间: < 2 秒
解码速度: ~500K pixels/秒
```

### 准确率

```
无噪声: 100% ✅
低噪声: 待测试
中噪声: 待测试
扩散噪声: 待测试
```

---

## 🔍 关键设计决策

### 1. 为什么不用颜色量化？

**原因**：颜色量化会导致不同 token 映射到相同颜色，违反唯一性要求。

**示例**：
```python
# 如果 color_levels = 32
token_id_1 = 0   → color = (0, 0, 0)
token_id_2 = 32  → color = (0, 0, 0)  # 冲突！
```

### 2. 为什么不用多像素编码？

**原因**：用户要求"每个像素对应一个文本 token"（1:1 映射）。

**如果使用多像素编码**：
- 容量会降低（例如：2 像素/ token → 容量减半）
- 违反 1:1 映射要求

### 3. 为什么不用错误纠正码（ECC）？

**原因**：每个像素对应一个 token，无法使用冗余编码。

**如果使用 ECC**：
- 需要多个像素编码一个 token
- 违反 1:1 映射要求

---

## ✅ 验证结果

### 测试 1: 基本编码/解码

```
原始文本: "静夜思 李白 床前明月光，疑是地上霜。举头望明月，低头思故乡。"
恢复文本: "静夜思 李白 床前明月光，疑是地上霜。举头望明月，低头思故乡。"
匹配: True ✅
Token 级别匹配: True ✅
```

### 测试 2: 大文本编码

```
文本长度: 1,006,237 字符
Token 数量: 812,924 tokens
图像尺寸: 1024×1024
编码时间: 0.67 秒
解码时间: 1.62 秒
准确率: 100% ✅
```

---

## 🎯 总结

### 最优方案：256 进制分解

1. ✅ **保证唯一性**：不同 token → 不同颜色
2. ✅ **可逆映射**：颜色 → token 唯一确定
3. ✅ **计算高效**：O(1) 时间复杂度
4. ✅ **颜色空间充足**：16,777,216 种颜色
5. ✅ **实现简单**：代码简洁易懂

### 为什么这是最好的解法？

- **数学保证**：256 进制分解在数学上保证了唯一性和可逆性
- **无冲突**：vocab_size << 颜色空间，不会产生冲突
- **高效**：编码和解码都是 O(1) 操作
- **简单**：实现简单，易于维护

### 预训练优势

- **无需问答对**：直接将文本编码到图像
- **自监督学习**：模型学习从噪声恢复原始图像
- **灵活**：可以处理任意长度的文本
- **高效**：编码速度快，适合大规模数据

---

**结论**：256 进制分解是当前场景下的最优方案，既保证了唯一性，又实现了高效的计算。对于预训练任务，这个方案特别适合，因为可以直接将各领域文本编码到图像，无需构造问答对。

