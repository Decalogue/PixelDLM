# æ¡ä»¶ç”Ÿæˆå¾®è°ƒè®¾è®¡æ–¹æ¡ˆ

## ğŸ¯ è®¾è®¡ç›®æ ‡

åœ¨é¢„è®­ç»ƒçš„åŸºç¡€ä¸Šï¼Œæ”¯æŒ**æ¡ä»¶ç”Ÿæˆ**ï¼šç»™å®š promptï¼ˆé—®é¢˜ï¼‰ï¼Œç”Ÿæˆ answerï¼ˆç­”æ¡ˆï¼‰ã€‚

---

## ğŸ“Š å½“å‰æ¶æ„åˆ†æ

### æ¨¡å‹å·²æ”¯æŒçš„æ¡ä»¶æœºåˆ¶

```python
def forward(self, x, t, condition=None, mask=None):
    # condition: Condition image patches [B, cond_patches, patch_dim]
    if condition is not None:
        cond_embed = self.condition_embed(condition)  # [B, cond_patches, embed_dim]
        x = torch.cat([cond_embed, x], dim=1)  # æ¡ä»¶æ”¾åœ¨åºåˆ—å‰é¢
```

**ç‰¹ç‚¹**ï¼š
- âœ… æ¡ä»¶ä½œä¸ºå›¾åƒ patches è¾“å…¥
- âœ… æ¡ä»¶æ”¾åœ¨åºåˆ—å‰é¢ï¼ˆç±»ä¼¼ prefixï¼‰
- âœ… ä½¿ç”¨ç‹¬ç«‹çš„ `condition_embed` å±‚

---

## ğŸ’¡ æ¡ä»¶ç”Ÿæˆæ–¹æ¡ˆè®¾è®¡

### æ–¹æ¡ˆ 1ï¼šPrompt å›¾åƒä½œä¸ºæ¡ä»¶ï¼ˆæ¨èï¼‰â­

**è®¾è®¡æ€è·¯**ï¼š
- å°† prompt æ–‡æœ¬ç¼–ç ä¸º**è¾ƒå°çš„å›¾åƒ**ï¼ˆå¦‚ 32Ã—32 æˆ– 16Ã—16ï¼‰
- å°† answer æ–‡æœ¬ç¼–ç ä¸º**ç›®æ ‡å›¾åƒ**ï¼ˆ64Ã—64ï¼‰
- æ¨¡å‹å­¦ä¹ ï¼š`promptå›¾åƒ + å™ªå£°` â†’ `answerå›¾åƒ`

**ä¼˜ç‚¹**ï¼š
- âœ… åˆ©ç”¨ç°æœ‰æ¶æ„ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹
- âœ… æ¡ä»¶ä¸ç›®æ ‡ä½¿ç”¨ç›¸åŒçš„ç¼–ç æ–¹å¼ï¼ˆtoken â†’ é¢œè‰²ï¼‰
- âœ… å®ç°ç®€å•ï¼Œåªéœ€ä¿®æ”¹ dataset å’Œè®­ç»ƒä»£ç 

**å®ç°**ï¼š

```python
# dataset.py ä¿®æ”¹
def __getitem__(self, idx):
    item = self.data[idx]
    
    if self.use_chat_template and 'prompt' in item:
        # æ¡ä»¶ç”Ÿæˆæ¨¡å¼
        prompt_text = item['prompt']
        answer_text = item['answer']
        
        # ç¼–ç  prompt ä¸ºè¾ƒå°çš„å›¾åƒï¼ˆ32Ã—32ï¼‰
        prompt_img = self._encode_text_to_image(
            prompt_text, 
            size=(32, 32)  # æ¡ä»¶å›¾åƒè¾ƒå°
        )
        
        # ç¼–ç  answer ä¸ºç›®æ ‡å›¾åƒï¼ˆ64Ã—64ï¼‰
        answer_img = self._encode_text_to_image(
            answer_text,
            size=(64, 64)  # ç›®æ ‡å›¾åƒ
        )
        
        return {
            'clean': answer_img_tensor,  # [3, 64, 64]
            'condition': prompt_img_tensor,  # [3, 32, 32]
            'mask': answer_mask_tensor,
            'text': answer_text,
        }
```

**è®­ç»ƒä»£ç ä¿®æ”¹**ï¼š

```python
# train.py
if condition is not None:
    # å°† condition å›¾åƒè½¬æ¢ä¸º patches
    condition_patches = model_ref.image_to_patches(condition)  # [B, cond_patches, patch_dim]
    clean_pred = model(noisy_target, t, condition=condition_patches, mask=mask)
else:
    # æ— æ¡ä»¶ç”Ÿæˆï¼ˆé¢„è®­ç»ƒæ¨¡å¼ï¼‰
    clean_pred = model(noisy_target, t, condition=None, mask=mask)
```

---

### æ–¹æ¡ˆ 2ï¼šClassifier-Free Guidanceï¼ˆCFGï¼‰â­

**è®¾è®¡æ€è·¯**ï¼š
- è®­ç»ƒæ—¶**éšæœºä¸¢å¼ƒæ¡ä»¶**ï¼ˆä¸€å®šæ¦‚ç‡è®¾ä¸º Noneï¼‰
- æ¨ç†æ—¶ä½¿ç”¨ guidance scale å¢å¼ºæ¡ä»¶æ§åˆ¶

**ä¼˜ç‚¹**ï¼š
- âœ… æ›´å¼ºçš„æ¡ä»¶æ§åˆ¶èƒ½åŠ›
- âœ… å¯ä»¥è°ƒèŠ‚æ¡ä»¶å¼ºåº¦ï¼ˆguidance scaleï¼‰
- âœ… ä¸šç•Œæ ‡å‡†åšæ³•ï¼ˆStable Diffusion ç­‰ï¼‰

**å®ç°**ï¼š

```python
# train.py
# è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒæ¡ä»¶ï¼ˆCFGï¼‰
cfg_dropout_prob = 0.1  # 10% çš„æ¦‚ç‡ä¸¢å¼ƒæ¡ä»¶
if condition is not None and random.random() > cfg_dropout_prob:
    condition_patches = model_ref.image_to_patches(condition)
else:
    condition_patches = None  # æ— æ¡ä»¶

clean_pred = model(noisy_target, t, condition=condition_patches, mask=mask)
```

**æ¨ç†æ—¶ä½¿ç”¨ CFG**ï¼š

```python
# inference.py
def generate_with_cfg(
    model, condition, guidance_scale=1.5, num_inference_steps=20
):
    # æ— æ¡ä»¶é¢„æµ‹
    pred_uncond = model(x, t, condition=None)
    
    # æœ‰æ¡ä»¶é¢„æµ‹
    pred_cond = model(x, t, condition=condition)
    
    # CFG: pred = pred_uncond + guidance_scale * (pred_cond - pred_uncond)
    pred = pred_uncond + guidance_scale * (pred_cond - pred_uncond)
    
    return pred
```

---

### æ–¹æ¡ˆ 3ï¼šæ–‡æœ¬åµŒå…¥ç›´æ¥ä½œä¸ºæ¡ä»¶ï¼ˆéœ€è¦æ¶æ„ä¿®æ”¹ï¼‰

**è®¾è®¡æ€è·¯**ï¼š
- ä½¿ç”¨æ–‡æœ¬ tokenizer çš„åµŒå…¥å±‚
- å°† prompt çš„ token embeddings ä½œä¸ºæ¡ä»¶

**ç¼ºç‚¹**ï¼š
- âŒ éœ€è¦ä¿®æ”¹æ¨¡å‹æ¶æ„ï¼ˆæ·»åŠ æ–‡æœ¬åµŒå…¥å±‚ï¼‰
- âŒ æ¡ä»¶ä¸ç›®æ ‡ä½¿ç”¨ä¸åŒçš„ç¼–ç æ–¹å¼
- âŒ å®ç°å¤æ‚

**ä¸æ¨è**ï¼Œå› ä¸ºæ–¹æ¡ˆ 1 æ›´ç®€å•ä¸”æœ‰æ•ˆã€‚

---

## ğŸ¯ æ¨èæ–¹æ¡ˆï¼šæ–¹æ¡ˆ 1 + æ–¹æ¡ˆ 2 ç»“åˆ

### å®Œæ•´è®¾è®¡

1. **æ•°æ®æ ¼å¼**ï¼š
   ```json
   {
     "prompt": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
     "answer": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯..."
   }
   ```

2. **æ¡ä»¶ç¼–ç **ï¼š
   - Prompt â†’ 32Ã—32 å›¾åƒï¼ˆæ¡ä»¶ï¼‰
   - Answer â†’ 64Ã—64 å›¾åƒï¼ˆç›®æ ‡ï¼‰

3. **è®­ç»ƒç­–ç•¥**ï¼š
   - ä½¿ç”¨ CFG dropoutï¼ˆ10-20% æ¦‚ç‡ä¸¢å¼ƒæ¡ä»¶ï¼‰
   - ä¿æŒé¢„è®­ç»ƒæƒé‡ï¼Œåªå¾®è°ƒæ¡ä»¶ç›¸å…³éƒ¨åˆ†ï¼ˆå¯é€‰ï¼‰

4. **æ¨ç†**ï¼š
   - æ”¯æŒæ— æ¡ä»¶ç”Ÿæˆï¼ˆ`condition=None`ï¼‰
   - æ”¯æŒæ¡ä»¶ç”Ÿæˆï¼ˆæä¾› prompt å›¾åƒï¼‰
   - æ”¯æŒ CFGï¼ˆå¯é€‰ï¼‰

---

## ğŸ“ å®ç°æ­¥éª¤

### Step 1: ä¿®æ”¹ dataset.py

```python
def __getitem__(self, idx):
    item = self.data[idx]
    
    if self.use_chat_template and 'prompt' in item and 'answer' in item:
        # æ¡ä»¶ç”Ÿæˆæ¨¡å¼
        prompt_text = item['prompt']
        answer_text = item['answer']
        
        # ç¼–ç  promptï¼ˆæ¡ä»¶ï¼Œè¾ƒå°å›¾åƒï¼‰
        prompt_img = self._encode_text_to_image(
            prompt_text,
            size=(32, 32),  # æ¡ä»¶å›¾åƒï¼š32Ã—32
            max_tokens=32 * 32
        )
        
        # ç¼–ç  answerï¼ˆç›®æ ‡ï¼Œå®Œæ•´å›¾åƒï¼‰
        answer_img = self._encode_text_to_image(
            answer_text,
            size=(64, 64),  # ç›®æ ‡å›¾åƒï¼š64Ã—64
            max_tokens=64 * 64
        )
        
        # è½¬æ¢ä¸º tensor
        prompt_tensor = torch.from_numpy(prompt_img).permute(2, 0, 1).float() / 255.0
        answer_tensor = torch.from_numpy(answer_img).permute(2, 0, 1).float() / 255.0
        
        # åˆ›å»º mask
        answer_mask = self._create_mask(answer_text, size=64)
        
        return {
            'clean': answer_tensor,
            'condition': prompt_tensor,  # æ–°å¢
            'mask': answer_mask,
            'text': answer_text,
        }
    else:
        # é¢„è®­ç»ƒæ¨¡å¼ï¼ˆæ— æ¡ä»¶ï¼‰
        # ... ç°æœ‰ä»£ç 
```

### Step 2: ä¿®æ”¹ train.py

```python
# æ·»åŠ  CFG dropout å‚æ•°
cfg_dropout_prob = 0.1  # 10% æ¦‚ç‡ä¸¢å¼ƒæ¡ä»¶

for batch_idx, batch in enumerate(pbar):
    clean = batch['clean'].to(device)
    mask = batch['mask'].to(device)
    condition = batch.get('condition', None)  # å¯èƒ½ä¸º Noneï¼ˆé¢„è®­ç»ƒæ¨¡å¼ï¼‰
    
    # CFG: éšæœºä¸¢å¼ƒæ¡ä»¶
    if condition is not None:
        condition = condition.to(device)
        if random.random() < cfg_dropout_prob:
            condition = None  # ä¸¢å¼ƒæ¡ä»¶
    
    # è½¬æ¢ä¸º patches
    if condition is not None:
        condition_patches = model_ref.image_to_patches(condition)
    else:
        condition_patches = None
    
    # Forward
    clean_pred = model(noisy_target, t, condition=condition_patches, mask=mask)
```

### Step 3: ä¿®æ”¹ inference.py

```python
def generate_with_condition(
    model, prompt_text, token_encoder, num_inference_steps=20
):
    # ç¼–ç  prompt ä¸ºå›¾åƒ
    prompt_img = token_encoder.encode(prompt_text, size=(32, 32))
    prompt_tensor = torch.from_numpy(prompt_img).permute(2, 0, 1).float() / 255.0
    prompt_patches = model.image_to_patches(prompt_tensor.unsqueeze(0))
    
    # æ¡ä»¶ç”Ÿæˆ
    generated_img = model.generate(
        condition=prompt_patches,
        num_inference_steps=num_inference_steps,
        device='cuda'
    )
    
    return generated_img
```

---

## ğŸ”§ å…³é”®è®¾è®¡å†³ç­–

### 1. æ¡ä»¶å›¾åƒå°ºå¯¸

**é€‰é¡¹**ï¼š
- **32Ã—32**ï¼ˆæ¨èï¼‰ï¼š1024 tokensï¼Œè¶³å¤Ÿå¤§å¤šæ•° prompt
- **16Ã—16**ï¼š256 tokensï¼Œé€‚åˆçŸ­ prompt
- **64Ã—64**ï¼š4096 tokensï¼Œä¸ç›®æ ‡ç›¸åŒï¼ˆå¯èƒ½æµªè´¹ï¼‰

**æ¨è 32Ã—32**ï¼š
- å¹³è¡¡å®¹é‡å’Œæ•ˆç‡
- å¤§å¤šæ•° prompt åœ¨ 1024 tokens ä»¥å†…
- æ¡ä»¶ä¸éœ€è¦å¤ªå¤§

### 2. CFG Dropout æ¦‚ç‡

**é€‰é¡¹**ï¼š
- **0.1**ï¼ˆ10%ï¼‰ï¼šè½»å¾®å¢å¼ºæ— æ¡ä»¶èƒ½åŠ›
- **0.2**ï¼ˆ20%ï¼‰ï¼šå¹³è¡¡æ¡ä»¶å’Œæ— æ¡ä»¶
- **0.0**ï¼ˆ0%ï¼‰ï¼šå®Œå…¨æ¡ä»¶ç”Ÿæˆï¼ˆä¸æ¨èï¼‰

**æ¨è 0.1-0.2**ï¼š
- ä¿æŒæ¨¡å‹çš„æ— æ¡ä»¶ç”Ÿæˆèƒ½åŠ›
- å¢å¼ºæ¡ä»¶æ§åˆ¶èƒ½åŠ›

### 3. å¾®è°ƒç­–ç•¥

**é€‰é¡¹ Aï¼šå…¨é‡å¾®è°ƒ**
- å¾®è°ƒæ‰€æœ‰å‚æ•°
- éœ€è¦è¾ƒå°å­¦ä¹ ç‡ï¼ˆå¦‚ 1e-6ï¼‰

**é€‰é¡¹ Bï¼šéƒ¨åˆ†å¾®è°ƒ**
- åªå¾®è°ƒ `condition_embed` å’Œæœ€åå‡ å±‚
- å†»ç»“é¢„è®­ç»ƒæƒé‡

**æ¨èé€‰é¡¹ A**ï¼š
- æ¡ä»¶ç”Ÿæˆéœ€è¦æ¨¡å‹ç†è§£æ¡ä»¶ä¸ç›®æ ‡çš„å…³ç³»
- å…¨é‡å¾®è°ƒæ•ˆæœæ›´å¥½

---

## ğŸ“Š è®­ç»ƒæ•°æ®æ ¼å¼

### é¢„è®­ç»ƒæ•°æ®ï¼ˆæ— æ¡ä»¶ï¼‰

```json
[
  {"text": "è¿™æ˜¯ä¸€æ®µæ–‡æœ¬..."},
  {"text": "å¦ä¸€æ®µæ–‡æœ¬..."}
]
```

### å¾®è°ƒæ•°æ®ï¼ˆæ¡ä»¶ç”Ÿæˆï¼‰

```json
[
  {
    "prompt": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
    "answer": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ ..."
  },
  {
    "prompt": "è§£é‡Šä¸€ä¸‹æ·±åº¦å­¦ä¹ ã€‚",
    "answer": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œ..."
  }
]
```

---

## âœ… æ€»ç»“

### æ¨èæ–¹æ¡ˆ

1. **æ¡ä»¶ç¼–ç **ï¼šPrompt â†’ 32Ã—32 å›¾åƒï¼ˆæ¡ä»¶ï¼‰ï¼ŒAnswer â†’ 64Ã—64 å›¾åƒï¼ˆç›®æ ‡ï¼‰
2. **è®­ç»ƒç­–ç•¥**ï¼šCFG dropoutï¼ˆ10-20% æ¦‚ç‡ä¸¢å¼ƒæ¡ä»¶ï¼‰
3. **å¾®è°ƒæ–¹å¼**ï¼šå…¨é‡å¾®è°ƒï¼Œä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡ï¼ˆ1e-6ï¼‰
4. **æ¨ç†æ”¯æŒ**ï¼šæ— æ¡ä»¶ + æ¡ä»¶ç”Ÿæˆ

### ä¼˜åŠ¿

- âœ… åˆ©ç”¨ç°æœ‰æ¶æ„ï¼Œå®ç°ç®€å•
- âœ… æ¡ä»¶ä¸ç›®æ ‡ä½¿ç”¨ç›¸åŒç¼–ç æ–¹å¼
- âœ… æ”¯æŒ CFGï¼Œå¢å¼ºæ¡ä»¶æ§åˆ¶
- âœ… ä¿æŒæ— æ¡ä»¶ç”Ÿæˆèƒ½åŠ›

---

**ä¿®æ”¹æ—¥æœŸ**: 2025-12-15
