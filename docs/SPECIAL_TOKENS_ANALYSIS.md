# ç‰¹æ®Š Token åœ¨é¢„è®­ç»ƒä¸­çš„ä½¿ç”¨åˆ†æ

## ğŸ” LLM é¢„è®­ç»ƒä¸­çš„ç‰¹æ®Š Token

### 1. EOS Tokenï¼ˆEnd of Sequenceï¼‰

**ä½œç”¨**ï¼šæ ‡è®°æ–‡æ¡£/åºåˆ—çš„ç»“æŸï¼Œç”¨äºåˆ†éš”ä¸åŒçš„æ–‡æ¡£

**ä½¿ç”¨æ–¹å¼**ï¼š
```python
# é¢„è®­ç»ƒæ—¶ï¼Œæ¯ä¸ªæ–‡æ¡£æœ«å°¾æ·»åŠ  EOS token
text = "æ–‡æ¡£å†…å®¹..."
tokens = tokenizer.encode(text, add_special_tokens=False)
tokens.append(tokenizer.eos_token_id)  # æ·»åŠ  EOS token
```

**é‡è¦æ€§**ï¼šâœ… **å¿…é¡»ä½¿ç”¨**
- è®©æ¨¡å‹å­¦ä¹ è¯†åˆ«æ–‡æ¡£è¾¹ç•Œ
- åœ¨ç”Ÿæˆæ—¶ï¼Œæ¨¡å‹çŸ¥é“ä½•æ—¶åœæ­¢ç”Ÿæˆ

### 2. BOS Tokenï¼ˆBeginning of Sequenceï¼‰

**ä½œç”¨**ï¼šæ ‡è®°åºåˆ—çš„å¼€å§‹

**ä½¿ç”¨æ–¹å¼**ï¼š
```python
# æœ‰äº›æ¨¡å‹åœ¨å¼€å¤´æ·»åŠ  BOS token
tokens = [tokenizer.bos_token_id] + tokenizer.encode(text, add_special_tokens=False)
```

**é‡è¦æ€§**ï¼šâš ï¸ **å¯é€‰**
- ä¸æ˜¯æ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨ BOS token
- Qwen2.5 æ²¡æœ‰ BOS tokenï¼ˆ`bos_token_id = None`ï¼‰

### 3. PAD Token

**ä½œç”¨**ï¼šç”¨äºå¡«å……çŸ­åºåˆ—ï¼Œä½¿ batch ä¸­çš„åºåˆ—é•¿åº¦ä¸€è‡´

**ä½¿ç”¨æ–¹å¼**ï¼š
```python
# ä¼ ç»Ÿåšæ³•ï¼šä½¿ç”¨ PAD token å¡«å……
padded_tokens = tokens + [tokenizer.pad_token_id] * (max_length - len(tokens))
```

**é‡è¦æ€§**ï¼šâŒ **é¢„è®­ç»ƒæ—¶é€šå¸¸ä¸ä½¿ç”¨**
- é¢„è®­ç»ƒæ—¶ä½¿ç”¨ **packing** ç­–ç•¥ï¼šå°†å¤šä¸ªçŸ­æ ·æœ¬æ‹¼æ¥æˆä¸€ä¸ªé•¿åºåˆ—
- é¿å…æµªè´¹è®¡ç®—èµ„æºåœ¨ padding ä¸Š
- æé«˜è®­ç»ƒæ•ˆç‡

---

## ğŸ“Š æˆ‘ä»¬çš„åœºæ™¯åˆ†æ

### å½“å‰å®ç°

```python
# å½“å‰ä»£ç ï¼šä¸æ·»åŠ ä»»ä½•ç‰¹æ®Š token
inputs = tokenizer(text, return_tensors="pt", add_special_tokens=False)
token_ids = inputs['input_ids'][0].tolist()

# ç¼–ç åˆ°å›¾åƒ
img = encode_token_ids_to_image(token_ids, size=(256, 256))
# å¦‚æœ token_ids ä¸å¤Ÿ 256Ã—256ï¼Œå‰©ä½™åƒç´ æ˜¯é»‘è‰² (0, 0, 0)
```

### é—®é¢˜

1. **æ²¡æœ‰ EOS token**ï¼šæ¨¡å‹æ— æ³•å­¦ä¹ è¯†åˆ«æ–‡æ¡£è¾¹ç•Œ
2. **é»‘è‰²åƒç´ ä½œä¸º padding**ï¼šä½†æ¨¡å‹ä¸çŸ¥é“è¿™æ˜¯ paddingï¼Œå¯èƒ½ä¼šé¢„æµ‹è¿™äº›ä½ç½®
3. **æ²¡æœ‰ mask**ï¼šè®­ç»ƒæ—¶ä¼šå¯¹ padding ä½ç½®è®¡ç®— lossï¼Œæµªè´¹è®¡ç®—èµ„æº

---

## âœ… è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: æ·»åŠ  EOS Token + é»‘è‰²åƒç´ ä½œä¸º Paddingï¼ˆæ¨èï¼‰

```python
# 1. åœ¨æ–‡æœ¬æœ«å°¾æ·»åŠ  EOS token
text = "æ–‡æ¡£å†…å®¹..."
tokens = tokenizer.encode(text, add_special_tokens=False)
if tokenizer.eos_token_id is not None:
    tokens.append(tokenizer.eos_token_id)

# 2. ç¼–ç åˆ°å›¾åƒ
img = encode_token_ids_to_image(tokens, size=(256, 256))
# å‰©ä½™åƒç´ ä¿æŒé»‘è‰² (0, 0, 0) ä½œä¸º padding

# 3. åˆ›å»º maskï¼ˆæ ‡è®°å“ªäº›åƒç´ æ˜¯ paddingï¼‰
mask = create_padding_mask(img)  # é»‘è‰²åƒç´  = padding
# mask[i, j] = 0 è¡¨ç¤º paddingï¼Œmask[i, j] = 1 è¡¨ç¤ºæœ‰æ•ˆåƒç´ 

# 4. è®­ç»ƒæ—¶ mask æ‰ padding
loss = compute_loss(predicted_img, clean_img, mask=mask)
```

**ä¼˜ç‚¹**ï¼š
- âœ… ç¬¦åˆ LLM é¢„è®­ç»ƒçš„åšæ³•ï¼ˆæ·»åŠ  EOS tokenï¼‰
- âœ… ç®€å•ç›´æ¥ï¼ˆé»‘è‰²åƒç´  = paddingï¼‰
- âœ… è®­ç»ƒæ—¶ mask æ‰ paddingï¼Œä¸æµªè´¹è®¡ç®—èµ„æº

**ç¼ºç‚¹**ï¼š
- âš ï¸ éœ€è¦ç¡®ä¿é»‘è‰² (0, 0, 0) ä¸ä¼šä¸çœŸå® token å†²çª
  - æ£€æŸ¥ï¼štoken_id=0 å¯¹åº”çš„é¢œè‰²æ˜¯ä»€ä¹ˆï¼Ÿ
  - å¦‚æœ token_id=0 å¯¹åº”é»‘è‰²ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†

### æ–¹æ¡ˆ 2: ä½¿ç”¨ PAD Tokenï¼ˆä¸æ¨èï¼‰

```python
# ä½¿ç”¨ PAD token å¡«å……
tokens = tokenizer.encode(text, add_special_tokens=False)
if tokenizer.eos_token_id is not None:
    tokens.append(tokenizer.eos_token_id)

# å¡«å……åˆ° 256Ã—256
max_tokens = 256 * 256
if len(tokens) < max_tokens:
    tokens.extend([tokenizer.pad_token_id] * (max_tokens - len(tokens)))

# ç¼–ç åˆ°å›¾åƒ
img = encode_token_ids_to_image(tokens, size=(256, 256))
```

**ç¼ºç‚¹**ï¼š
- âŒ ä¸ç¬¦åˆ LLM é¢„è®­ç»ƒçš„åšæ³•ï¼ˆé¢„è®­ç»ƒæ—¶é€šå¸¸ä¸ä½¿ç”¨ PAD tokenï¼‰
- âŒ æµªè´¹è®¡ç®—èµ„æºï¼ˆå¯¹ padding ä½ç½®è®¡ç®— lossï¼‰
- âŒ éœ€è¦é¢å¤–çš„ mask æœºåˆ¶

---

## ğŸ”§ å®ç°å»ºè®®

### 1. æ·»åŠ  EOS Token

```python
def _encode_text_to_image(self, text: str) -> np.ndarray:
    """å°†æ–‡æœ¬ç¼–ç ä¸ºå›¾åƒ"""
    # Tokenize æ–‡æœ¬
    inputs = self.tokenizer(text, return_tensors="pt", add_special_tokens=False)
    token_ids = inputs['input_ids'][0].tolist()
    
    # æ·»åŠ  EOS tokenï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if self.tokenizer.eos_token_id is not None:
        token_ids.append(self.tokenizer.eos_token_id)
    
    # ç¼–ç åˆ°å›¾åƒ...
```

### 2. åˆ›å»º Padding Mask

```python
def create_padding_mask(img: np.ndarray) -> np.ndarray:
    """
    åˆ›å»º padding mask
    
    Args:
        img: å›¾åƒæ•°ç»„ (H, W, 3)
    
    Returns:
        mask: (H, W)ï¼Œ1 è¡¨ç¤ºæœ‰æ•ˆåƒç´ ï¼Œ0 è¡¨ç¤º padding
    """
    # é»‘è‰²åƒç´  (0, 0, 0) è¡¨ç¤º padding
    mask = (img.sum(axis=2) > 0).astype(np.float32)
    return mask
```

### 3. è®­ç»ƒæ—¶ä½¿ç”¨ Mask

```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­
clean_img = batch['clean']  # [B, 3, H, W]
mask = batch['mask']  # [B, H, W]

# é¢„æµ‹
predicted_img = model(noisy_img, timestep)

# è®¡ç®— lossï¼ˆåªå¯¹æœ‰æ•ˆåƒç´ ï¼‰
loss = mse_loss(predicted_img * mask, clean_img * mask)
loss = loss.sum() / mask.sum()  # å½’ä¸€åŒ–
```

---

## ğŸ“ æ£€æŸ¥ Token ID 0 çš„é¢œè‰²

éœ€è¦æ£€æŸ¥ `token_id=0` å¯¹åº”çš„é¢œè‰²ï¼Œç¡®ä¿ä¸ä¼šä¸é»‘è‰² padding å†²çªï¼š

```python
# æ£€æŸ¥ token_id=0 çš„é¢œè‰²
token_id = 0
color = token_id_to_color(token_id)  # (r, g, b)
print(f"token_id=0 å¯¹åº”çš„é¢œè‰²: {color}")

# å¦‚æœæ˜¯ (0, 0, 0)ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
if color == (0, 0, 0):
    print("âš ï¸ è­¦å‘Š: token_id=0 å¯¹åº”é»‘è‰²ï¼Œä¸ padding å†²çªï¼")
    print("è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨ç‰¹æ®Šçš„ padding token_idï¼ˆå¦‚ pad_token_idï¼‰")
```

---

## âœ… æœ€ç»ˆå»ºè®®

1. **æ·»åŠ  EOS token**ï¼šåœ¨æ¯ä¸ªæ–‡æœ¬æœ«å°¾æ·»åŠ  EOS tokenï¼ˆå¦‚æœå­˜åœ¨ï¼‰
2. **é»‘è‰²åƒç´ ä½œä¸º padding**ï¼šå‰©ä½™åƒç´ ä¿æŒé»‘è‰² (0, 0, 0)
3. **åˆ›å»º padding mask**ï¼šæ ‡è®°å“ªäº›åƒç´ æ˜¯ padding
4. **è®­ç»ƒæ—¶ mask æ‰ padding**ï¼šåªå¯¹æœ‰æ•ˆåƒç´ è®¡ç®— loss
5. **æ£€æŸ¥ token_id=0**ï¼šç¡®ä¿ä¸ä¼šä¸é»‘è‰² padding å†²çª

---

## ğŸ¯ æ€»ç»“

### LLM é¢„è®­ç»ƒä¸­çš„ç‰¹æ®Š Token

- âœ… **EOS token**ï¼šå¿…é¡»ä½¿ç”¨ï¼ˆæ ‡è®°æ–‡æ¡£è¾¹ç•Œï¼‰
- âš ï¸ **BOS token**ï¼šå¯é€‰ï¼ˆQwen2.5 æ²¡æœ‰ï¼‰
- âŒ **PAD token**ï¼šé¢„è®­ç»ƒæ—¶é€šå¸¸ä¸ä½¿ç”¨ï¼ˆä½¿ç”¨ packing ç­–ç•¥ï¼‰

### æˆ‘ä»¬çš„å®ç°

- âœ… æ·»åŠ  EOS token åˆ°æ–‡æœ¬æœ«å°¾
- âœ… ä½¿ç”¨é»‘è‰²åƒç´ ä½œä¸º padding
- âœ… åˆ›å»º padding mask
- âœ… è®­ç»ƒæ—¶ mask æ‰ padding

**ç»“è®º**ï¼šåº”è¯¥æ·»åŠ  EOS tokenï¼Œå¹¶ä½¿ç”¨é»‘è‰²åƒç´ ä½œä¸º paddingï¼ŒåŒæ—¶åˆ›å»º mask åœ¨è®­ç»ƒæ—¶å¿½ç•¥ padding éƒ¨åˆ†ã€‚
