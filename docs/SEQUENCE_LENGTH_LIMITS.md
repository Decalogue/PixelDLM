# 模型序列长度限制分析

## 📊 当前架构序列长度限制

### 目标图像（主序列）

**计算公式**：
```python
num_patches = (img_size // patch_size) ** 2
```

**当前配置**（JiT-B/4, 64×64）：
- `img_size = 64`
- `patch_size = 4`
- `num_patches = (64 // 4) ** 2 = 16 ** 2 = 256`

**最大序列长度**：**256 patches**

---

### 条件图像（条件序列）

**当前配置**：
- `max_cond_patches = 256`（默认）
- 支持最大 256 个 patches 的条件图像

**示例**：
- 32×32 图像，patch_size=4 → 8×8 = **64 patches** ✅
- 64×64 图像，patch_size=4 → 16×16 = **256 patches** ✅
- 128×128 图像，patch_size=4 → 32×32 = **1024 patches** ❌（超过限制）

---

### 总序列长度

**无条件生成**：
- 序列长度：`num_patches = 256`

**条件生成**：
- 序列长度：`cond_patches + num_patches`
- 最大：`256 + 256 = 512 patches`

---

## 🎯 序列长度总结

| 模式 | 目标序列 | 条件序列 | 总序列长度 |
|------|---------|---------|-----------|
| 无条件 | 256 | 0 | **256** |
| 条件（32×32） | 256 | 64 | **320** |
| 条件（64×64） | 256 | 256 | **512**（最大） |

---

## ⚠️ 限制说明

### 1. 目标图像序列长度

- **固定**：由 `img_size` 和 `patch_size` 决定
- **当前**：256 patches（64×64, patch_size=4）
- **无法动态调整**：位置编码是固定的

### 2. 条件图像序列长度

- **可配置**：通过 `max_cond_patches` 参数
- **当前默认**：256 patches
- **超过限制时**：会截断或填充

### 3. Transformer 理论限制

- **理论上**：Transformer 可以处理任意长度的序列
- **实际限制**：
  - 注意力矩阵：O(n²) 复杂度
  - 显存限制：序列越长，显存占用越大
  - 位置编码：需要支持相应长度

---

## 📈 不同配置的序列长度

### JiT-B/4 (64×64, patch_size=4)

```
目标图像: 16×16 = 256 patches
条件图像: 最大 16×16 = 256 patches
总序列: 最大 512 patches
```

### JiT-B/16 (256×256, patch_size=16)

```
目标图像: 16×16 = 256 patches
条件图像: 最大 16×16 = 256 patches
总序列: 最大 512 patches
```

---

## ✅ 总结

### 当前架构序列长度限制

1. **目标图像**：256 patches（固定）
2. **条件图像**：最大 256 patches（可配置）
3. **总序列长度**：最大 **512 patches**

### 注意事项

- ✅ 当前配置（64×64）足够大多数场景
- ⚠️ 如果需要更大的条件图像，需要增加 `max_cond_patches`
- ⚠️ 序列长度增加会带来显存和计算开销

---

**修改日期**: 2025-12-15




