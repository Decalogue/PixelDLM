# é¢„è®­ç»ƒæ¨¡å‹è¯´æ˜

## ğŸ¯ å½“å‰çŠ¶æ€

**JiT-B/4 æ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œéœ€è¦ä»é›¶å¼€å§‹è®­ç»ƒã€‚**

---

## ğŸ“‹ æ¨¡å‹æ¶æ„

### å½“å‰å®ç°

`build_jit_model` å‡½æ•°åªæ˜¯åˆ›å»ºæ¨¡å‹æ¶æ„ï¼š

```python
def build_jit_model(
    model_name: str = 'JiT-B/4',
    img_size: int = 64,
    predict_clean: bool = True,
) -> JiT:
    """Build JiT model from config"""
    configs = {
        'JiT-B/4': {'embed_dim': 768, 'depth': 12, 'num_heads': 12, 'patch_size': 4},
        # ...
    }
    
    model = JiT(
        img_size=img_size,
        patch_size=config['patch_size'],
        embed_dim=config['embed_dim'],
        depth=config['depth'],
        num_heads=config['num_heads'],
        predict_clean=predict_clean,
    )
    
    return model  # è¿”å›éšæœºåˆå§‹åŒ–çš„æ¨¡å‹
```

### åˆå§‹åŒ–æ–¹å¼

æ¨¡å‹ä½¿ç”¨**éšæœºåˆå§‹åŒ–**ï¼š
- ä½ç½®åµŒå…¥ï¼š`nn.init.normal_(self.pos_embed, std=0.02)`
- çº¿æ€§å±‚ï¼š`nn.init.trunc_normal_(m.weight, std=0.02)`
- AdaLNZeroï¼šé›¶åˆå§‹åŒ–ï¼ˆscale å’Œ shift MLP çš„æœ€åä¸€å±‚ï¼‰

---

## ğŸ”„ è®­ç»ƒæµç¨‹

### 1. ä»é›¶å¼€å§‹è®­ç»ƒ

```bash
# ç›´æ¥è®­ç»ƒï¼Œæ²¡æœ‰é¢„è®­ç»ƒæƒé‡
./train.sh
```

### 2. ä¿å­˜æ£€æŸ¥ç‚¹

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šä¿å­˜ï¼š
- `checkpoint_epoch_{N}.pth` - å®šæœŸæ£€æŸ¥ç‚¹
- `best_model.pth` - æœ€ä½³æ¨¡å‹ï¼ˆloss æœ€ä½ï¼‰

### 3. æ¢å¤è®­ç»ƒ

```bash
# ä½¿ç”¨ --resume å‚æ•°æ¢å¤è®­ç»ƒ
python train.py \
    --resume ./run/jit_v1/checkpoint_epoch_10.pth \
    --data_path ./data/train \
    ...
```

---

## ğŸ’¡ ä¸ºä»€ä¹ˆæ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Ÿ

### 1. è¿™æ˜¯æ–°æ¶æ„

JiT (Just image Transformer) æ˜¯åŸºäºè®ºæ–‡çš„æ–°æ¶æ„ï¼š
- ä¸“é—¨ä¸ºåƒç´ ç©ºé—´æ‰©æ•£è®¾è®¡
- æ²¡æœ‰ç°æˆçš„é¢„è®­ç»ƒæƒé‡

### 2. ä»»åŠ¡ç‰¹æ®Šæ€§

- **ä»»åŠ¡**ï¼šæ–‡æœ¬ token â†’ å›¾åƒé¢œè‰² â†’ æ–‡æœ¬ token
- **ç‰¹æ®Šæ€§**ï¼štoken åˆ°é¢œè‰²çš„æ˜ å°„æ˜¯ç¡®å®šçš„ï¼Œä½†è§†è§‰ä¸Šåƒå™ªå£°
- **é¢„è®­ç»ƒæ•°æ®**ï¼šéœ€è¦å¤§é‡æ–‡æœ¬æ•°æ®ï¼Œè€Œä¸æ˜¯å›¾åƒæ•°æ®

### 3. ä»é›¶è®­ç»ƒçš„ä¼˜åŠ¿

- **ä»»åŠ¡å¯¹é½**ï¼šæ¨¡å‹ä»é›¶å­¦ä¹ æ–‡æœ¬ token çš„æ‰©æ•£è¿‡ç¨‹
- **æ— åå·®**ï¼šä¸å—è‡ªç„¶å›¾åƒé¢„è®­ç»ƒçš„å½±å“
- **çµæ´»æ€§**ï¼šå¯ä»¥æ ¹æ®ä»»åŠ¡è°ƒæ•´æ¶æ„

---

## ğŸš€ è®­ç»ƒå»ºè®®

### 1. è®­ç»ƒç­–ç•¥

ç”±äºæ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œå»ºè®®ï¼š

1. **ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡**ï¼š
   ```bash
   LR=5e-6  # ä»é›¶è®­ç»ƒï¼Œéœ€è¦æ›´å°çš„å­¦ä¹ ç‡
   ```

2. **è¶³å¤Ÿçš„è®­ç»ƒæ—¶é—´**ï¼š
   ```bash
   EPOCHS=100  # ä»é›¶è®­ç»ƒéœ€è¦æ›´å¤š epoch
   ```

3. **Warmup**ï¼š
   ```bash
   WARMUP_EPOCHS=5  # å¸®åŠ©æ¨¡å‹ç¨³å®šè®­ç»ƒ
   ```

### 2. ç›‘æ§æŒ‡æ ‡

- **Loss ä¸‹é™**ï¼šåº”è¯¥ç¨³å®šä¸‹é™
- **Token æ¢å¤å‡†ç¡®ç‡**ï¼šè®­ç»ƒåæµ‹è¯•è§£ç å‡†ç¡®ç‡
- **æ–‡æœ¬æ¢å¤å‡†ç¡®ç‡**ï¼šæœ€ç»ˆç›®æ ‡

---

## ğŸ“ æœªæ¥å¯èƒ½çš„é¢„è®­ç»ƒæ¨¡å‹

### å¦‚æœå°†æ¥æœ‰é¢„è®­ç»ƒæ¨¡å‹

å¯ä»¥è¿™æ ·åŠ è½½ï¼š

```python
def load_pretrained_jit(
    model_name: str = 'JiT-B/4',
    pretrained_path: str = None,
    img_size: int = 64,
):
    """Load pretrained JiT model"""
    model = build_jit_model(model_name, img_size)
    
    if pretrained_path:
        checkpoint = torch.load(pretrained_path, map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"Loaded pretrained model from {pretrained_path}")
    
    return model
```

### é¢„è®­ç»ƒæ•°æ®æ¥æº

å¯èƒ½çš„é¢„è®­ç»ƒæ•°æ®ï¼š
- å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®ï¼ˆå¦‚å½“å‰ä½¿ç”¨çš„ novelsï¼‰
- å¤šè¯­è¨€æ–‡æœ¬æ•°æ®
- ä¸åŒé¢†åŸŸçš„æ–‡æœ¬æ•°æ®

---

## âœ… æ€»ç»“

1. **å½“å‰çŠ¶æ€**ï¼šJiT-B/4 æ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œéœ€è¦ä»é›¶è®­ç»ƒ
2. **è®­ç»ƒæ–¹å¼**ï¼šä½¿ç”¨ `train.sh` ä»é›¶å¼€å§‹è®­ç»ƒ
3. **ä¿å­˜æ£€æŸ¥ç‚¹**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
4. **æ¢å¤è®­ç»ƒ**ï¼šå¯ä»¥ä½¿ç”¨ `--resume` å‚æ•°æ¢å¤è®­ç»ƒ

**è¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºè¿™æ˜¯æ–°æ¶æ„ï¼Œéœ€è¦ä»é›¶å¼€å§‹è®­ç»ƒï¼**

---

**ä¿®æ”¹æ—¥æœŸ**: 2024-12-15




